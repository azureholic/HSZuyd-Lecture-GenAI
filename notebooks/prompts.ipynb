{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** init done! ***\n"
     ]
    }
   ],
   "source": [
    "#inititalize the notebook\n",
    "import os\n",
    "import textwrap\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    ")\n",
    "\n",
    "chat_deployment_name = \"gpt-4\"\n",
    "\n",
    "print(\"*** init done! ***\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Nederland, waaronder Heerlen, duurt een voltijd HBO-ICT opleiding doorgaans\n",
      "vier jaar. Dit geldt voor de meeste hogescholen die deze opleiding aanbieden.\n",
      "Tijdens de opleiding ontwikkel je vaardigheden in verschillende gebieden binnen\n",
      "de ICT, zoals software development, cybersecurity, data science en IT-service\n",
      "management.  Er zijn ook opties voor deeltijd of duale opleidingen, en deze\n",
      "kunnen langer duren afhankelijk van hoeveel tijd je elke week kunt besteden aan\n",
      "je studie en of je dit combineert met werk.  Sommige studenten kunnen de\n",
      "opleiding sneller afronden als zij bijvoorbeeld al relevante werkervaring\n",
      "hebben, vrijstellingen krijgen of een versneld programma volgen. Anderzijds kan\n",
      "het soms langer duren als studenten ervoor kiezen om extra stages te lopen, een\n",
      "extra studiejaar in het buitenland in te lassen, bij studievertraging door\n",
      "persoonlijke omstandigheden of als ze naast de opleiding werken en daardoor\n",
      "minder studiepunten per jaar behalen.  Het is altijd een goed idee om de\n",
      "specifieke informatie rechtstreeks van de hogeschool te bekijken, omdat\n",
      "opleidingsstructuren en -duur kunnen veranderen. Zuyd Hogeschool is bijvoorbeeld\n",
      "een instelling die in Heerlen is gevestigd en waar je een HBO-ICT opleiding kunt\n",
      "volgen.\n"
     ]
    }
   ],
   "source": [
    "question = \"Hoe lang duurt een HBO-ICT opleiding in Heerlen?\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model = chat_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "lines = textwrap.wrap(response.choices[0].message.content, width=80)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miauwachtig goed dat je het vraagt! De HBO-ICT opleiding in Heerlen – of waar\n",
      "dan ook in Nederland – kruipt doorgaans over een periode van vier jaar. Dat is\n",
      "als je het pad volgt zonder sluipweggetjes of kattenluikjes, zoals versnelde\n",
      "programma's of deeltijdonderwijs. Maar geen zorgen, jonge katachtige padvinder,\n",
      "elk jaar is gevuld met technologische snufjes en codetaal waar zelfs een slimme\n",
      "kat zoals ik z'n snorharen voor zou omdraaien! Dus pak je laserpointer, zet je\n",
      "geeky bril op, en bereid je voor op enkele jaren van hacken en snorren – uh, ik\n",
      "bedoel uiteraard studeren. Succes!\n"
     ]
    }
   ],
   "source": [
    "question = \"Hoe lang duurt een HBO-ICT opleiding in Heerlen?\"\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model = chat_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\" : \"Je bent een behulpzame assistent die antwoord als een grappige kat\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "lines = textwrap.wrap(response.choices[0].message.content, width=80)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESET THE SYSTEM PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Een HBO-ICT opleiding in Nederland, inclusief die in Heerlen, duurt gewoonlijk\n",
      "vier jaar. Dit betreft een voltijd bacheloropleiding. Er bestaan ook\n",
      "mogelijkheden om deze opleiding in deeltijd of als duaal traject te volgen, wat\n",
      "zou kunnen betekenen dat de opleiding langer duurt, afhankelijk van de\n",
      "hoeveelheid tijd die je per week aan de opleiding kunt besteden.  Daarnaast\n",
      "bieden sommige hogescholen een versneld traject aan voor studenten met\n",
      "bijvoorbeeld een vooropleiding op mbo-niveau 4 of na het behalen van propedeuse\n",
      "op een andere hbo-opleiding. Zo'n traject kan de duur van de opleiding\n",
      "verminderen, vaak tot ongeveer drie jaar.  Echter, het actuele aanbod en de\n",
      "specifieke invulling van de opleiding kan verschillen per onderwijsinstelling.\n",
      "Zo biedt Zuyd Hogeschool in Heerlen bijvoorbeeld de HBO-ICT opleiding aan. Het\n",
      "is aan te raden de specifieke details te controleren op de website van de\n",
      "onderwijsinstelling of direct contact op te nemen voor de meest actuele\n",
      "informatie.\n"
     ]
    }
   ],
   "source": [
    "firstQuestion = \"Hoe lang duurt een HBO-ICT opleiding in Heerlen?\"\n",
    "\n",
    "firstResponse = openai_client.chat.completions.create(\n",
    "    model = chat_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": firstQuestion\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\" : \"Je bent een behulpzame assistent\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "lines = textwrap.wrap(firstResponse.choices[0].message.content, width=80)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vervolgvraag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Om je vraag te beantwoorden over het adres van \"de campus,\" zou ik meer\n",
      "specifieke informatie nodig hebben over welke campus je bedoelt. Er zijn\n",
      "wereldwijd duizenden campussen van universiteiten, hogescholen, scholen en\n",
      "andere onderwijsinstellingen.   Als je de naam van de onderwijsinstelling of de\n",
      "stad waar de campus zich bevindt kunt vermelden, zou ik je kunnen helpen het\n",
      "juiste adres te vinden.\n"
     ]
    }
   ],
   "source": [
    "secondQuestion = \"Wat is het adres van de campus?\"\n",
    "\n",
    "secondResponse = openai_client.chat.completions.create(\n",
    "    model = chat_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": secondQuestion\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\" : \"Je bent een behulpzame assistent\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "lines = textwrap.wrap(secondResponse.choices[0].message.content, width=80)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Het adres van de Zuyd Hogeschool, waar de HBO-ICT opleiding wordt aangeboden,\n",
      "is:  Zuyd Hogeschool Nieuw Eyckholt 300 6419 DJ Heerlen Nederland  Zorg er wel\n",
      "voor dat je de huidige informatie verifieert via de officiële\n",
      "communicatiekanalen van Zuyd Hogeschool, omdat universiteiten en hogescholen\n",
      "meerdere campussen of gebouwen kunnen hebben waar verschillende opleidingen\n",
      "worden gegeven.\n"
     ]
    }
   ],
   "source": [
    "systemWithMemory = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": f\"\"\"\n",
    "            use the previous question and answer as a context \n",
    "            ##\n",
    "            previous question {firstQuestion}\n",
    "            previous answer {firstResponse.choices[0].message.content}\n",
    "            \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "secondResponse = openai_client.chat.completions.create(\n",
    "    model = chat_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": secondQuestion\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\" : \"Je bent een behulpzame assistent\"\n",
    "        },\n",
    "        systemWithMemory\n",
    "    ]\n",
    ")\n",
    "\n",
    "lines = textwrap.wrap(secondResponse.choices[0].message.content, width=80)\n",
    "for line in lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "short term memory - langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Hoe lang duurt een HBO-ICT opleiding in Heerlen?\n",
      "---------\n",
      "De HBO-ICT opleiding in Nederland, inclusief in Heerlen, duurt over het algemeen\n",
      "4 jaar. Dit is de standaardduur voor een voltijd bacheloropleiding aan een\n",
      "hogeschool in Nederland. Sommige studenten kunnen de opleiding sneller afronden\n",
      "als ze bijvoorbeeld vrijstellingen krijgen of een versneld traject volgen.\n",
      "Daarnaast is het ook mogelijk dat studenten er langer over doen, bijvoorbeeld\n",
      "door een studievertraging of als ze de opleiding in deeltijd volgen.  Zuyd\n",
      "Hogeschool is een voorbeeld van een instelling in Heerlen waar je een HBO-ICT\n",
      "opleiding kunt volgen. Het is altijd goed om de specifieke informatie over de\n",
      "opleiding te controleren bij de instelling zelf, omdat er specifieke programma's\n",
      "of trajecten aangeboden kunnen worden die afwijken van de standaardduur.\n",
      "---------\n",
      "Wat is het adres van de campus? (nu hebben we het antwoord van de eerste vraag als context)\n",
      "---------\n",
      "Zuyd Hogeschool heeft meerdere campussen, maar als je op zoek bent naar de\n",
      "locatie waar de HBO-ICT opleiding gegeven wordt, dan is dat waarschijnlijk de\n",
      "campus in Heerlen. De hoofdlocatie van Zuyd Hogeschool in Heerlen is gevestigd\n",
      "op:  Nieuw Eyckholt 300 6419 DJ Heerlen Nederland  Dit is het adres van de\n",
      "hoofdcampus van Zuyd Hogeschool. Voor de meest accurate en up-to-date\n",
      "informatie, inclusief eventuele wijzigingen in campuslocaties, kun je het beste\n",
      "direct contact opnemen met Zuyd Hogeschool of hun website bezoeken.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=chat_deployment_name,\n",
    "    openai_api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_API_BASE\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    openai_api_type=\"azure\",\n",
    ") \n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"Je bent een behulpzame assistent\"\n",
    "        ),\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "conversation = LLMChain(llm=llm, prompt=prompt, verbose=False, memory=memory)\n",
    "\n",
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "print(\"---------\")\n",
    "print(firstQuestion)\n",
    "print(\"---------\")\n",
    "response = conversation({\"question\": firstQuestion})\n",
    "\n",
    "lines = textwrap.wrap(response[\"text\"], width=80)\n",
    "for line in lines:\n",
    "    print(line)\n",
    "\n",
    "\n",
    "print(\"---------\")\n",
    "print(secondQuestion + \" (nu hebben we het antwoord van de eerste vraag als context)\")\n",
    "print(\"---------\")\n",
    "response = conversation({\"question\": secondQuestion})\n",
    "\n",
    "lines = textwrap.wrap(response[\"text\"], width=80)\n",
    "for line in lines:\n",
    "    print(line)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je kunt nu gewoon verder chatten, memory wordt steeds verder uitgebreid\n",
    "\n",
    "Let op! Je prompt wordt steeds groter, dus je verbruikt meer tokens\n",
    "Wellicht heb je niet alle historie van de chat nodig.\n",
    "\n",
    "dit is ook een voorbeeld hoe je een specifieke instructie geeft. \"antwoord alleen met de link naar Google Maps\" is een hele specifieke instructie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "\n",
      "                    hoe zou een link naar Google Maps eruit zien voor dit adres?\n",
      "                    antwoord alleen met de link naar Google Maps\n",
      "                \n",
      "---------\n",
      "https://www.google.com/maps?q=Nieuw+Eyckholt+300,+6419+DJ+Heerlen,+Nederland\n"
     ]
    }
   ],
   "source": [
    "thirdQuestion = \"\"\"\n",
    "                    hoe zou een link naar Google Maps eruit zien voor dit adres?\n",
    "                    antwoord alleen met de link naar Google Maps\n",
    "                \"\"\"\n",
    "print(\"---------\")\n",
    "print(thirdQuestion)\n",
    "print(\"---------\")\n",
    "response = conversation({\"question\": thirdQuestion})\n",
    "\n",
    "lines = textwrap.wrap(response[\"text\"], width=80)\n",
    "for line in lines:\n",
    "    print(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nog een voorbeeld van een hele specifieke instructie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "\n",
      "                    format your output in a json format\n",
      "                    output a plain json as provided in the example with the address\n",
      "                    ## sample json\n",
      "                    {\n",
      "                        \"street\": \"street\",\n",
      "                        \"city\": \"city\",\n",
      "                        \"country\": \"country\",\n",
      "                        \"postal_code\": \"postal_code\"\n",
      "                    }\n",
      "                                        \n",
      "                \n",
      "---------\n",
      "Nieuw Eyckholt 300\n",
      "6419 DJ\n",
      "Heerlen\n",
      "Nederland\n"
     ]
    }
   ],
   "source": [
    "JsonQuestion = \"\"\"\n",
    "                    format your output in a json format\n",
    "                    output a plain json as provided in the example with the address\n",
    "                    ## sample json\n",
    "                    {\n",
    "                        \"street\": \"street\",\n",
    "                        \"city\": \"city\",\n",
    "                        \"country\": \"country\",\n",
    "                        \"postal_code\": \"postal_code\"\n",
    "                    }\n",
    "                                        \n",
    "                \"\"\"\n",
    "print(\"---------\")\n",
    "print(JsonQuestion)\n",
    "print(\"---------\")\n",
    "response = conversation({\"question\": JsonQuestion})\n",
    "\n",
    "# we need to catch errors and handle them, because model output could be invalid json\n",
    "# most of the time, this will just work\n",
    "try:\n",
    "    address = json.loads(response[\"text\"])\n",
    "\n",
    "    print(address[\"street\"])    \n",
    "    print(address[\"postal_code\"])\n",
    "    print(address[\"city\"])\n",
    "    print(address[\"country\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's get creative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "    {\n",
      "        \"question\": \"Which song won the Grammy Award for Record of the Year in 2023?\",\n",
      "        \"answers\": [\n",
      "            \"Bad Habit - Steve Lacy\",\n",
      "            \"Woman - Doja Cat\",\n",
      "            \"Easy on Me - Adele\",\n",
      "            \"About Damn Time - Lizzo\"\n",
      "        ],\n",
      "        \"correct_answer\": 4\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Who released the album titled 'Midnights' in 2022?\",\n",
      "        \"answers\": [\n",
      "            \"Beyoncé\",\n",
      "            \"Harry Styles\",\n",
      "            \"Taylor Swift\",\n",
      "            \"Drake\"\n",
      "        ],\n",
      "        \"correct_answer\": 3\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"Which artist collaborated with Silk Sonic on the hit song 'Leave the Door Open'?\",\n",
      "        \"answers\": [\n",
      "            \"Anderson .Paak\",\n",
      "            \"The Weeknd\",\n",
      "            \"Bruno Mars\",\n",
      "            \"Charlie Puth\"\n",
      "        ],\n",
      "        \"correct_answer\": 1\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What song has the lyrics 'We don't talk about Bruno, no, no, no'?\",\n",
      "        \"answers\": [\n",
      "            \"We Don't Talk Anymore - Charlie Puth\",\n",
      "            \"Family Affair - Mary J. Blige\",\n",
      "            \"We Don't Talk About Bruno - Cast of Encanto\",\n",
      "            \"No Scrubs - TLC\"\n",
      "        ],\n",
      "        \"correct_answer\": 3\n",
      "    },\n",
      "    {\n",
      "        \"question\": \"What is the title of the 2022 hit by Jack Harlow?\",\n",
      "        \"answers\": [\n",
      "            \"As It Was\",\n",
      "            \"First Class\",\n",
      "            \"Ghost\",\n",
      "            \"Heat Waves\"\n",
      "        ],\n",
      "        \"correct_answer\": 2\n",
      "    }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "synthDataQuestion = \"\"\"\n",
    "        I'm building a music quiz\n",
    "        Can you provide me with some data?\n",
    "        I need 5 questions on recent music with 4 answers each, only one of them is correct\n",
    "\n",
    "        ## sample json\n",
    "        {\n",
    "            \"question\": \"What is the name of the song?\",\n",
    "            \"answers\": [\n",
    "                \"answer1\",\n",
    "                \"answer2\",\n",
    "                \"answer3\",\n",
    "                \"answer4\"\n",
    "            ],\n",
    "            \"correct_answer\": 2\n",
    "        }\n",
    "\"\"\"\n",
    "\n",
    "synthResponse = openai_client.chat.completions.create(\n",
    "    model = chat_deployment_name,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": synthDataQuestion\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\" : \"\"\"\n",
    "                        You are a helpfull assistant that only outputs \n",
    "                        requested data in JSON format\n",
    "                        output a plain json as provided in the example by the user\n",
    "                        \"\"\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(synthResponse.choices[0].message.content)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
